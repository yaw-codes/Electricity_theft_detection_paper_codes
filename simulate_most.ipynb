{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6367f67f-1453-4455-9ce5-95a365afb8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import classification_report,accuracy_score,mean_absolute_error,mean_squared_error, confusion_matrix,roc_auc_score,precision_recall_fscore_support\n",
    "from sklearn.linear_model import LogisticRegressionCV,LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import (\n",
    "   \n",
    "    BatchNormalization,\n",
    ")\n",
    "from tensorflow.python.keras.layers import Dense,Conv1D, Flatten,Conv2D,Dropout,MaxPool2D,MaxPool1D\n",
    "from tensorflow.keras import Sequential\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c68521-88b1-4038-a981-987746c87df3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c166d02-2ced-42c5-a561-299a3839aec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of the test size xomparing to the whole dataset\n",
    "test_set_size = 0.1 \n",
    "#set to 1 to over-sample the minority class\n",
    "oversampling_flag = 0 \n",
    "#percentage of the minority class after the oversampling comparing to majority class\n",
    "oversampling_percentage = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b662b9c-42b9-4e9e-9be8-1264ac7e23cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "939c4096-865d-42cc-8216-66b05ba0c52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition of fxns\n",
    "\n",
    "data = pd.read_csv(\"./Data_clean/min_max_both_inter_scaled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b2057e6-8ed8-4b9f-9f71-825134207ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.FLAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "461fbab2-8050-46ad-81c2-3e3ee5a79a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop([\"FLAG\",\"CONS_NO\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfa79154-9fe0-4c0d-bc15-ed6ae6de1958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3579     0\n",
       "3580     0\n",
       "3581     0\n",
       "3582     0\n",
       "3583     0\n",
       "        ..\n",
       "40251    0\n",
       "40252    0\n",
       "40253    0\n",
       "40254    0\n",
       "40255    0\n",
       "Name: FLAG, Length: 36677, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[y == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9a7a18d-36a3-4da8-a941-f6194d0c22b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Consumers: 36677\n"
     ]
    }
   ],
   "source": [
    "print(f\"Normal Consumers: {len(y[y == 0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f27c03b-bcdf-4ed1-be27-34c30276d3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consumers with Fraud: 3579\n"
     ]
    }
   ],
   "source": [
    "print(f\"Consumers with Fraud: {len(y[y == 1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2726f2e9-1d41-4e2f-bedd-47e36fb8dae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Consumers: 40256\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Consumers: {len(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c75fa19d-9d04-4ce9-9735-4aaab633a2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification assuming no fraud: 91.11\n"
     ]
    }
   ],
   "source": [
    "print(f\"Classification assuming no fraud: {len(y[y == 0])/len(y)*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bafa297-a314-46ea-aca3-0d22dfd9c55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns = pd.to_datetime(X.columns)\n",
    "X = X.reindex(X.columns,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4040fcb1-4593-407f-8276-f3b9f5646063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2014-01-01</th>\n",
       "      <th>2014-01-02</th>\n",
       "      <th>2014-01-03</th>\n",
       "      <th>2014-01-04</th>\n",
       "      <th>2014-01-05</th>\n",
       "      <th>2014-01-06</th>\n",
       "      <th>2014-01-07</th>\n",
       "      <th>2014-01-08</th>\n",
       "      <th>2014-01-09</th>\n",
       "      <th>2014-01-10</th>\n",
       "      <th>...</th>\n",
       "      <th>2016-10-22</th>\n",
       "      <th>2016-10-23</th>\n",
       "      <th>2016-10-24</th>\n",
       "      <th>2016-10-25</th>\n",
       "      <th>2016-10-26</th>\n",
       "      <th>2016-10-27</th>\n",
       "      <th>2016-10-28</th>\n",
       "      <th>2016-10-29</th>\n",
       "      <th>2016-10-30</th>\n",
       "      <th>2016-10-31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264158</td>\n",
       "      <td>0.296902</td>\n",
       "      <td>0.297637</td>\n",
       "      <td>0.350616</td>\n",
       "      <td>0.201613</td>\n",
       "      <td>0.321919</td>\n",
       "      <td>0.342154</td>\n",
       "      <td>0.277402</td>\n",
       "      <td>0.337003</td>\n",
       "      <td>0.247970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333740</td>\n",
       "      <td>0.547089</td>\n",
       "      <td>0.543432</td>\n",
       "      <td>0.527583</td>\n",
       "      <td>0.653459</td>\n",
       "      <td>0.581835</td>\n",
       "      <td>0.565681</td>\n",
       "      <td>0.495276</td>\n",
       "      <td>0.432795</td>\n",
       "      <td>0.416336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242798</td>\n",
       "      <td>0.286581</td>\n",
       "      <td>0.327142</td>\n",
       "      <td>0.282600</td>\n",
       "      <td>0.371304</td>\n",
       "      <td>0.394049</td>\n",
       "      <td>0.340220</td>\n",
       "      <td>0.365049</td>\n",
       "      <td>0.274071</td>\n",
       "      <td>0.222138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.048145</td>\n",
       "      <td>0.112494</td>\n",
       "      <td>0.144199</td>\n",
       "      <td>0.058008</td>\n",
       "      <td>0.064819</td>\n",
       "      <td>0.105683</td>\n",
       "      <td>0.091123</td>\n",
       "      <td>0.066463</td>\n",
       "      <td>0.062940</td>\n",
       "      <td>0.060357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313762</td>\n",
       "      <td>0.220056</td>\n",
       "      <td>0.178957</td>\n",
       "      <td>0.123532</td>\n",
       "      <td>0.123297</td>\n",
       "      <td>0.138093</td>\n",
       "      <td>0.156646</td>\n",
       "      <td>0.235791</td>\n",
       "      <td>0.211602</td>\n",
       "      <td>0.184829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147734</td>\n",
       "      <td>0.174809</td>\n",
       "      <td>0.172454</td>\n",
       "      <td>0.043555</td>\n",
       "      <td>0.024132</td>\n",
       "      <td>0.024720</td>\n",
       "      <td>0.112419</td>\n",
       "      <td>0.024720</td>\n",
       "      <td>0.022366</td>\n",
       "      <td>0.035903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40251</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288360</td>\n",
       "      <td>0.273369</td>\n",
       "      <td>0.242504</td>\n",
       "      <td>0.265432</td>\n",
       "      <td>0.263668</td>\n",
       "      <td>0.249559</td>\n",
       "      <td>0.223986</td>\n",
       "      <td>0.299824</td>\n",
       "      <td>0.316578</td>\n",
       "      <td>0.223986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40252</th>\n",
       "      <td>0.164334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.348144</td>\n",
       "      <td>0.368229</td>\n",
       "      <td>0.353621</td>\n",
       "      <td>0.186853</td>\n",
       "      <td>0.245892</td>\n",
       "      <td>0.345709</td>\n",
       "      <td>0.267194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233719</td>\n",
       "      <td>0.402921</td>\n",
       "      <td>0.189897</td>\n",
       "      <td>0.314060</td>\n",
       "      <td>0.220329</td>\n",
       "      <td>0.282410</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.378576</td>\n",
       "      <td>0.368229</td>\n",
       "      <td>0.290323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40253</th>\n",
       "      <td>0.048013</td>\n",
       "      <td>0.096026</td>\n",
       "      <td>0.076159</td>\n",
       "      <td>0.081126</td>\n",
       "      <td>0.127483</td>\n",
       "      <td>0.114238</td>\n",
       "      <td>0.073675</td>\n",
       "      <td>0.057947</td>\n",
       "      <td>0.101821</td>\n",
       "      <td>0.069536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081954</td>\n",
       "      <td>0.050497</td>\n",
       "      <td>0.053808</td>\n",
       "      <td>0.045530</td>\n",
       "      <td>0.040563</td>\n",
       "      <td>0.042219</td>\n",
       "      <td>0.065397</td>\n",
       "      <td>0.054636</td>\n",
       "      <td>0.032285</td>\n",
       "      <td>0.053808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40254</th>\n",
       "      <td>0.349472</td>\n",
       "      <td>0.313470</td>\n",
       "      <td>0.398924</td>\n",
       "      <td>0.355680</td>\n",
       "      <td>0.347610</td>\n",
       "      <td>0.361680</td>\n",
       "      <td>0.369543</td>\n",
       "      <td>0.496379</td>\n",
       "      <td>0.255328</td>\n",
       "      <td>0.286365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.323609</td>\n",
       "      <td>0.340989</td>\n",
       "      <td>0.269812</td>\n",
       "      <td>0.214980</td>\n",
       "      <td>0.248293</td>\n",
       "      <td>0.230706</td>\n",
       "      <td>0.252845</td>\n",
       "      <td>0.272295</td>\n",
       "      <td>0.275812</td>\n",
       "      <td>0.214980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40255</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385120</td>\n",
       "      <td>0.625091</td>\n",
       "      <td>0.304522</td>\n",
       "      <td>0.316557</td>\n",
       "      <td>0.233042</td>\n",
       "      <td>0.290299</td>\n",
       "      <td>0.296499</td>\n",
       "      <td>0.419402</td>\n",
       "      <td>0.261123</td>\n",
       "      <td>0.191466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40256 rows × 1034 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       2014-01-01  2014-01-02  2014-01-03  2014-01-04  2014-01-05  2014-01-06  \\\n",
       "0        0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1        0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2        0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "3        0.048145    0.112494    0.144199    0.058008    0.064819    0.105683   \n",
       "4        0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "40251    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "40252    0.164334    0.000000    0.000000    0.348144    0.368229    0.353621   \n",
       "40253    0.048013    0.096026    0.076159    0.081126    0.127483    0.114238   \n",
       "40254    0.349472    0.313470    0.398924    0.355680    0.347610    0.361680   \n",
       "40255    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "       2014-01-07  2014-01-08  2014-01-09  2014-01-10  ...  2016-10-22  \\\n",
       "0        0.000000    0.000000    0.000000    0.000000  ...    0.264158   \n",
       "1        0.000000    0.000000    0.000000    0.000000  ...    0.333740   \n",
       "2        0.000000    0.000000    0.000000    0.000000  ...    0.242798   \n",
       "3        0.091123    0.066463    0.062940    0.060357  ...    0.313762   \n",
       "4        0.000000    0.000000    0.000000    0.000000  ...    0.147734   \n",
       "...           ...         ...         ...         ...  ...         ...   \n",
       "40251    0.000000    0.000000    0.000000    0.000000  ...    0.288360   \n",
       "40252    0.186853    0.245892    0.345709    0.267194  ...    0.233719   \n",
       "40253    0.073675    0.057947    0.101821    0.069536  ...    0.081954   \n",
       "40254    0.369543    0.496379    0.255328    0.286365  ...    0.323609   \n",
       "40255    0.000000    0.000000    0.000000    0.000000  ...    0.385120   \n",
       "\n",
       "       2016-10-23  2016-10-24  2016-10-25  2016-10-26  2016-10-27  2016-10-28  \\\n",
       "0        0.296902    0.297637    0.350616    0.201613    0.321919    0.342154   \n",
       "1        0.547089    0.543432    0.527583    0.653459    0.581835    0.565681   \n",
       "2        0.286581    0.327142    0.282600    0.371304    0.394049    0.340220   \n",
       "3        0.220056    0.178957    0.123532    0.123297    0.138093    0.156646   \n",
       "4        0.174809    0.172454    0.043555    0.024132    0.024720    0.112419   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "40251    0.273369    0.242504    0.265432    0.263668    0.249559    0.223986   \n",
       "40252    0.402921    0.189897    0.314060    0.220329    0.282410    0.225806   \n",
       "40253    0.050497    0.053808    0.045530    0.040563    0.042219    0.065397   \n",
       "40254    0.340989    0.269812    0.214980    0.248293    0.230706    0.252845   \n",
       "40255    0.625091    0.304522    0.316557    0.233042    0.290299    0.296499   \n",
       "\n",
       "       2016-10-29  2016-10-30  2016-10-31  \n",
       "0        0.277402    0.337003    0.247970  \n",
       "1        0.495276    0.432795    0.416336  \n",
       "2        0.365049    0.274071    0.222138  \n",
       "3        0.235791    0.211602    0.184829  \n",
       "4        0.024720    0.022366    0.035903  \n",
       "...           ...         ...         ...  \n",
       "40251    0.299824    0.316578    0.223986  \n",
       "40252    0.378576    0.368229    0.290323  \n",
       "40253    0.054636    0.032285    0.053808  \n",
       "40254    0.272295    0.275812    0.214980  \n",
       "40255    0.419402    0.261123    0.191466  \n",
       "\n",
       "[40256 rows x 1034 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12d75ba4-3f22-4e69-91b7-b111383b3e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8cf1989-f2a9-45f8-a9c6-aa8884380321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#oversampling of minority class (imbalanced learning)\n",
    "over = SMOTE(sampling_strategy=0.2,random_state=0)\n",
    "over_x_train,over_y_train = over.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "260ca825-315c-4c32-ae3d-a042f52e38f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7335"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(over_y_train[over_y_train==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c699e27f-3c5c-450d-9809-c9e72e53607a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Consumers: 36677\n",
      "Consumers with Fraud: 7335\n",
      "Total Consumers: 44012\n",
      "Classification assuming no fraud: 83.33\n"
     ]
    }
   ],
   "source": [
    "print(f\"Normal Consumers: {len(over_y_train[over_y_train == 0])}\")\n",
    "print(f\"Consumers with Fraud: {len(over_y_train[over_y_train == 1])}\")\n",
    "print(f\"Total Consumers: {len(over_y_train)}\")\n",
    "print(f\"Classification assuming no fraud: {len(over_y_train[over_y_train == 0])/len(over_y_train)*100:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a10a2d-f206-4b3c-a723-19d72f8ef90e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "730b58ac-29f0-4b4d-91e9-4e94e0d4ef42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(y_test,prediction):\n",
    "    print(\"Accuracy: \",100*accuracy_score(y_test,prediction))\n",
    "    print(\"RMSE: \",mean_squared_error(y_test,prediction))\n",
    "    print(\"MAE: \", mean_absolute_error(y_test,prediction))\n",
    "    print(\"F1: \",precision_recall_fscore_support(y_test,prediction))\n",
    "    print(\"Classification report\", classification_report(y_test,prediction))\n",
    "    print(\"AUC: \", 100*roc_auc_score(y_test,prediction))\n",
    "    print(confusion_matrix(y_test,prediction), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "272f365c-3481-4fb2-af57-a9b6e882bdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(X_train,X_test,y_train,y_test):\n",
    "    print(\"SVM:: \")\n",
    "    model = SVC(random_state=0)\n",
    "    model.fit(X_train,y_train)\n",
    "    prediction = model.predict(X_test)\n",
    "    results(y_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "965e0fcd-4b5f-49fd-8fba-ecaac73f8531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF(x_train,x_test,y_train,y_test):\n",
    "    print(\"Random Forest: \")\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=100,min_samples_leaf=1, max_features= \"auto\", random_state=0,n_jobs=-1,max_depth=10)\n",
    "    model.fit(x_train,y_train)\n",
    "    prediction = model.predict(x_test)\n",
    "    results(y_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90c63b21-88d0-4b4f-afe6-b93b5ccd1fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DT(x_train,x_test,y_train,y_test):\n",
    "    print(\"Descision Tree:\")\n",
    "    model = DecisionTreeClassifier(random_state=0)\n",
    "    model.fit(x_train,y_train)\n",
    "    prediction = model.predict(x_test)\n",
    "    results(y_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "403d3d25-4e1a-4dca-9c59-0498165daef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR(X_train, X_test, y_train, y_test):\n",
    "    print('Logistic Regression:')\n",
    "    '''\n",
    "    # Parameters selection \n",
    "    param_grid = {'C': [0.1,1,10,100],'solver': ['newton-cg', 'lbfgs']}\n",
    "    grid = GridSearchCV(LogisticRegression(max_iter=1000,random_state=0), param_grid=param_grid, n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    df = pd.DataFrame(grid.cv_results_)\n",
    "    print(df[['param_C', 'param_solver', 'mean_test_score', 'rank_test_score']])\n",
    "    '''\n",
    "    model = LogisticRegression(C=1000, max_iter=1000, n_jobs=-1, solver='newton-cg')\n",
    "    model.fit(X_train, y_train)\n",
    "    prediction = model.predict(X_test)\n",
    "    results(y_test, prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "519b2d92-0bd9-4df7-bc8f-b248504d4320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN1D(X_train, X_test, y_train, y_test):\n",
    "    print('1D - Convolutional Neural Network:')\n",
    "\n",
    "    # Transforming the dataset into tensors\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "    y_test = keras.utils.to_categorical(y_test,num_classes=2)\n",
    "    y_train = keras.utils.to_categorical(y_train,num_classes=2)\n",
    "\n",
    "    # Model creation\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(100, kernel_size=7, input_shape=(1034, 1), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss=keras.losses.binary_crossentropy,\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # model.fit(X_train, y_train, epochs=1, validation_split=0.1, shuffle=False, verbose=1)\n",
    "    model.fit(X_train, y_train, epochs=20, validation_split=0, shuffle=False, verbose=1)\n",
    "    prediction = model.predict(X_test)\n",
    "    classes_x=np.argmax(prediction,axis=1)\n",
    "    model.summary()\n",
    "    results(y_test, classes_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66e97482-bdef-4ca5-9907-5d839e383490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN(X_train, X_test, y_train, y_test):\n",
    "    print('Artificial Neural Network:')\n",
    "    # for i in range(4,100,3):\n",
    "    #     print(\"Epoch:\",i)\n",
    "        # Transforming the dataset into tensors\n",
    "  \n",
    "    # Model creation\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1000, input_dim=1034, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss=keras.losses.binary_crossentropy,\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # model.fit(X_train, y_train, validation_split=0, epochs=i, shuffle=True, verbose=0)\n",
    "    model.fit(X_train, y_train, validation_split=0, epochs=20, shuffle=True, verbose=1)\n",
    "    prediction = model.predict(X_test)\n",
    "    classes_x=np.argmax(prediction,axis=1)\n",
    "    model.summary()\n",
    "    results(y_test, classes_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1339356f-d07b-4a25-9341-00d2913c68a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd6ca2d-a8f1-433d-b24c-9b483f6e0520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e5f3983-cec2-4d6b-a227-af1195a18eac",
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f26726be-8eaf-49ea-a0b4-10841170a9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Neural Network:\n",
      "Epoch 1/20\n",
      "1007/1007 [==============================] - 10s 8ms/step - loss: 0.2978 - accuracy: 0.9114\n",
      "Epoch 2/20\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.2759 - accuracy: 0.9125\n",
      "Epoch 3/20\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.2669 - accuracy: 0.9137\n",
      "Epoch 4/20\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.2582 - accuracy: 0.9160\n",
      "Epoch 5/20\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.2507 - accuracy: 0.9163\n",
      "Epoch 6/20\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.2415 - accuracy: 0.9191\n",
      "Epoch 7/20\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.2335 - accuracy: 0.9215\n",
      "Epoch 8/20\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.2253 - accuracy: 0.9246\n",
      "Epoch 9/20\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.2151 - accuracy: 0.9285\n",
      "Epoch 10/20\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.2095 - accuracy: 0.9306\n",
      "Epoch 11/20\n",
      "1007/1007 [==============================] - 9s 9ms/step - loss: 0.2020 - accuracy: 0.9317\n",
      "Epoch 12/20\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.1914 - accuracy: 0.9348\n",
      "Epoch 13/20\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.1876 - accuracy: 0.9367\n",
      "Epoch 14/20\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.1768 - accuracy: 0.9403\n",
      "Epoch 15/20\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.1723 - accuracy: 0.9427\n",
      "Epoch 16/20\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.1629 - accuracy: 0.9448\n",
      "Epoch 17/20\n",
      "1007/1007 [==============================] - 7s 7ms/step - loss: 0.1602 - accuracy: 0.9458\n",
      "Epoch 18/20\n",
      "1007/1007 [==============================] - 7s 7ms/step - loss: 0.1524 - accuracy: 0.9484\n",
      "Epoch 19/20\n",
      "1007/1007 [==============================] - 7s 7ms/step - loss: 0.1469 - accuracy: 0.9499\n",
      "Epoch 20/20\n",
      "1007/1007 [==============================] - 7s 7ms/step - loss: 0.1434 - accuracy: 0.9520\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " module_wrapper_12 (ModuleWr  (None, 1000)             1035000   \n",
      " apper)                                                          \n",
      "                                                                 \n",
      " module_wrapper_13 (ModuleWr  (None, 100)              100100    \n",
      " apper)                                                          \n",
      "                                                                 \n",
      " module_wrapper_14 (ModuleWr  (None, 100)              10100     \n",
      " apper)                                                          \n",
      "                                                                 \n",
      " module_wrapper_15 (ModuleWr  (None, 100)              10100     \n",
      " apper)                                                          \n",
      "                                                                 \n",
      " module_wrapper_16 (ModuleWr  (None, 10)               1010      \n",
      " apper)                                                          \n",
      "                                                                 \n",
      " module_wrapper_17 (ModuleWr  (None, 1)                11        \n",
      " apper)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,156,321\n",
      "Trainable params: 1,156,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Accuracy:  90.80973671137606\n",
      "RMSE:  0.09190263288623944\n",
      "MAE:  0.09190263288623944\n",
      "F1:  (array([0.90809737, 0.        ]), array([1., 0.]), array([0.95183546, 0.        ]), array([7312,  740], dtype=int64))\n",
      "Classification report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      7312\n",
      "           1       0.00      0.00      0.00       740\n",
      "\n",
      "    accuracy                           0.91      8052\n",
      "   macro avg       0.45      0.50      0.48      8052\n",
      "weighted avg       0.82      0.91      0.86      8052\n",
      "\n",
      "AUC:  50.0\n",
      "[[7312    0]\n",
      " [ 740    0]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "ANN(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d947ae-d9dc-4e2e-a732-1d9f3b935613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D - Convolutional Neural Network:\n",
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "CNN1D(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db4485d-280f-4e0f-8e98-f7e9211ab253",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF(X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e22c848-a616-43ba-a978-147c078573ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71113bd2-8d86-4a88-b1e1-1f0568a01aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94609e97-7f49-4515-a700-4bb13e55ee9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Neural Network:\n",
      "Epoch 1/20\n",
      "1007/1007 [==============================] - 10s 7ms/step - loss: 0.2980 - accuracy: 0.9118\n",
      "Epoch 2/20\n",
      "1007/1007 [==============================] - 7s 7ms/step - loss: 0.2765 - accuracy: 0.9118\n",
      "Epoch 3/20\n",
      "1007/1007 [==============================] - 7s 7ms/step - loss: 0.2681 - accuracy: 0.9126\n",
      "Epoch 4/20\n",
      "1007/1007 [==============================] - 7s 7ms/step - loss: 0.2628 - accuracy: 0.9131\n",
      "Epoch 5/20\n",
      "1007/1007 [==============================] - 7s 7ms/step - loss: 0.2548 - accuracy: 0.9155\n",
      "Epoch 6/20\n",
      "1007/1007 [==============================] - 7s 7ms/step - loss: 0.2440 - accuracy: 0.9188\n",
      "Epoch 7/20\n",
      "1007/1007 [==============================] - 7s 7ms/step - loss: 0.2385 - accuracy: 0.9206\n",
      "Epoch 8/20\n",
      "1007/1007 [==============================] - 7s 7ms/step - loss: 0.2291 - accuracy: 0.9234\n",
      "Epoch 9/20\n",
      "1007/1007 [==============================] - 7s 7ms/step - loss: 0.2196 - accuracy: 0.9270\n",
      "Epoch 10/20\n",
      "1007/1007 [==============================] - 7s 7ms/step - loss: 0.2105 - accuracy: 0.9294\n",
      "Epoch 11/20\n",
      "1007/1007 [==============================] - 7s 7ms/step - loss: 0.2011 - accuracy: 0.9322\n",
      "Epoch 12/20\n",
      "1007/1007 [==============================] - 7s 7ms/step - loss: 0.1954 - accuracy: 0.9342\n",
      "Epoch 13/20\n",
      "1007/1007 [==============================] - 7s 7ms/step - loss: 0.1886 - accuracy: 0.9373\n",
      "Epoch 14/20\n",
      "1007/1007 [==============================] - 7s 7ms/step - loss: 0.1815 - accuracy: 0.9392\n",
      "Epoch 15/20\n",
      "1007/1007 [==============================] - 7s 7ms/step - loss: 0.1737 - accuracy: 0.9411\n",
      "Epoch 16/20\n",
      "1007/1007 [==============================] - 7s 7ms/step - loss: 0.1670 - accuracy: 0.9441\n",
      "Epoch 17/20\n",
      "1007/1007 [==============================] - 7s 7ms/step - loss: 0.1613 - accuracy: 0.9448\n",
      "Epoch 18/20\n",
      "1007/1007 [==============================] - 7s 7ms/step - loss: 0.1542 - accuracy: 0.9475\n",
      "Epoch 19/20\n",
      "1007/1007 [==============================] - 7s 7ms/step - loss: 0.1500 - accuracy: 0.9493\n",
      "Epoch 20/20\n",
      "1007/1007 [==============================] - 7s 7ms/step - loss: 0.1428 - accuracy: 0.9524\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8696/3636020311.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mANN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mCNN1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mRF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mLR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mDT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8696/4265765873.py\u001b[0m in \u001b[0;36mANN\u001b[1;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# model.fit(X_train, y_train, validation_split=0, epochs=i, shuffle=True, verbose=0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mresults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "SVM(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07f9259-909b-4d85-8609-7f4e65a34fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = train_test_split(over_x_train, over_y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f84a19f-c9d6-498f-9061-9fee272ecc63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bf6ca4-5d02-4043-88f1-28f21b544021",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN(X_train, X_test, y_train, y_test)\n",
    "CNN1D(X_train, X_test, y_train, y_test)\n",
    "RF(X_train, X_test, y_train, y_test)\n",
    "LR(X_train, X_test, y_train, y_test)\n",
    "DT(X_train, X_test, y_train, y_test)\n",
    "SVM(X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4987e08-55ff-4897-8c20-7fb7f2081bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
